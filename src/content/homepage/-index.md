---
# Banner
banner:
  title: "Fusing Vision and Language"
  subtitle: "A Tutorial on Vision-Language Models for Multimodal Content Analysis"
  image: "/images/banner.png"
---

### Summary
The increasing availability of multimodal data, including images and videos, has led to a surge of interest in multimodal models that combine visual and textual information. This tutorial will provide an in-depth introduction to the latest advances in multimodal models, with a focus on large vision-language models. Through a combination of theoretical explanations, code demonstrations, and hands-on exercises, participants will learn how to apply these models to a range of image and video analysis tasks, including image captioning, visual concept detection, and image retrieval. By the end of the tutorial, attendees will have a solid understanding of the strengths and limitations of these models, enabling them to implement their own multimodal applications.

### Program

- **13:30 - 13:45** Welcome Session
- **13:30 - 15:30** From Vision to Vision-Language Models
- **15:30 - 16:00** Coffee Break
- **16:00 - 17:30** Generative AI and Domain Adaptation
- **17:30 - 18:00** Discussion and Closing Session

### Resources

- TIB AV-Analytics: https://service.tib.eu/tibava

### Contact

- Dr. Eric MÃ¼ller-Budack, [eric.mueller@tib.eu](mailto:eric.mueller@tib.eu)
- Sushil Awale, [sushil.awale@tib.eu](mailto:sushil.awale@tib.eu)